{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pylab inline\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.misc import imread\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from matplotlib import pyplot\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "\n",
    "# To stop potential randomness\n",
    "seed = 128\n",
    "rng = np.random.RandomState(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = os.path.abspath('/Users/shubhamjain/Downloads/AV/identify the digits/')\n",
    "data_dir = os.path.join(root_dir, 'data')\n",
    "sub_dir = os.path.join(root_dir, 'sub')\n",
    "\n",
    "## reading train file only\n",
    "train = pd.read_csv(os.path.join(data_dir, 'Train', 'train.csv'))\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = os.path.join(data_dir, 'Train', 'Images', 'train', img_name)\n",
    "\n",
    "img = imread(filepath, flatten=True)\n",
    "\n",
    "pylab.imshow(img, cmap='gray')\n",
    "pylab.axis('off')\n",
    "pylab.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#storing images in numpy arrays\n",
    "temp = []\n",
    "for img_name in train.filename:\n",
    " image_path = os.path.join(data_dir, 'Train', 'Images', 'train', img_name)\n",
    " img = imread(image_path, flatten=True)\n",
    " img = img.astype('float32')\n",
    " temp.append(img)\n",
    " \n",
    "x_train = np.stack(temp)\n",
    "\n",
    "x_train /= 255.0\n",
    "x_train = x_train.reshape(-1, 784).astype('float32')\n",
    "\n",
    "y_train = keras.utils.np_utils.to_categorical(train.label.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_size = int(x_train.shape[0]*0.7)\n",
    "\n",
    "x_train, x_test = x_train[:split_size], x_train[split_size:]\n",
    "y_train, y_test = y_train[:split_size], y_train[split_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import keras modules\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define vars\n",
    "input_num_units = 784\n",
    "hidden1_num_units = 500\n",
    "hidden2_num_units = 500\n",
    "hidden3_num_units = 500\n",
    "hidden4_num_units = 500\n",
    "hidden5_num_units = 500\n",
    "output_num_units = 10\n",
    "\n",
    "epochs = 10\n",
    "batch_size = 128\n",
    "\n",
    "model = Sequential([\n",
    " Dense(output_dim=hidden1_num_units, input_dim=input_num_units, activation='relu'),\n",
    " Dense(output_dim=hidden2_num_units, input_dim=hidden1_num_units, activation='relu'),\n",
    " Dense(output_dim=hidden3_num_units, input_dim=hidden2_num_units, activation='relu'),\n",
    " Dense(output_dim=hidden4_num_units, input_dim=hidden3_num_units, activation='relu'),\n",
    " Dense(output_dim=hidden5_num_units, input_dim=hidden4_num_units, activation='relu'),\n",
    "\n",
    "Dense(output_dim=output_num_units, input_dim=hidden5_num_units, activation='softmax'),\n",
    " ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "trained_model_5d = model.fit(x_train, y_train, nb_epoch=epochs, batch_size=batch_size, validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import regularizers\n",
    "\n",
    "model = Sequential([\n",
    " Dense(output_dim=hidden1_num_units, input_dim=input_num_units, activation='relu',\n",
    " kernel_regularizer=regularizers.l2(0.0001)),\n",
    " Dense(output_dim=hidden2_num_units, input_dim=hidden1_num_units, activation='relu',\n",
    " kernel_regularizer=regularizers.l2(0.0001)),\n",
    " Dense(output_dim=hidden3_num_units, input_dim=hidden2_num_units, activation='relu',\n",
    " kernel_regularizer=regularizers.l2(0.0001)),\n",
    " Dense(output_dim=hidden4_num_units, input_dim=hidden3_num_units, activation='relu',\n",
    " kernel_regularizer=regularizers.l2(0.0001)),\n",
    " Dense(output_dim=hidden5_num_units, input_dim=hidden4_num_units, activation='relu',\n",
    " kernel_regularizer=regularizers.l2(0.0001)),\n",
    "\n",
    "Dense(output_dim=output_num_units, input_dim=hidden5_num_units, activation='softmax'),\n",
    " ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "trained_model_5d = model.fit(x_train, y_train, nb_epoch=epochs, batch_size=batch_size, validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## l1\n",
    "\n",
    "model = Sequential([\n",
    " Dense(output_dim=hidden1_num_units, input_dim=input_num_units, activation='relu',\n",
    " kernel_regularizer=regularizers.l1(0.0001)),\n",
    " Dense(output_dim=hidden2_num_units, input_dim=hidden1_num_units, activation='relu',\n",
    " kernel_regularizer=regularizers.l1(0.0001)),\n",
    " Dense(output_dim=hidden3_num_units, input_dim=hidden2_num_units, activation='relu',\n",
    " kernel_regularizer=regularizers.l1(0.0001)),\n",
    " Dense(output_dim=hidden4_num_units, input_dim=hidden3_num_units, activation='relu',\n",
    " kernel_regularizer=regularizers.l1(0.0001)),\n",
    " Dense(output_dim=hidden5_num_units, input_dim=hidden4_num_units, activation='relu',\n",
    " kernel_regularizer=regularizers.l1(0.0001)),\n",
    "\n",
    "Dense(output_dim=output_num_units, input_dim=hidden5_num_units, activation='softmax'),\n",
    " ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "trained_model_5d = model.fit(x_train, y_train, nb_epoch=epochs, batch_size=batch_size, validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## dropout\n",
    "\n",
    "from keras.layers.core import Dropout\n",
    "model = Sequential([\n",
    " Dense(output_dim=hidden1_num_units, input_dim=input_num_units, activation='relu'),\n",
    " Dropout(0.25),\n",
    " Dense(output_dim=hidden2_num_units, input_dim=hidden1_num_units, activation='relu'),\n",
    " Dropout(0.25),\n",
    " Dense(output_dim=hidden3_num_units, input_dim=hidden2_num_units, activation='relu'),\n",
    " Dropout(0.25),\n",
    " Dense(output_dim=hidden4_num_units, input_dim=hidden3_num_units, activation='relu'),\n",
    " Dropout(0.25),\n",
    " Dense(output_dim=hidden5_num_units, input_dim=hidden4_num_units, activation='relu'),\n",
    " Dropout(0.25),\n",
    "\n",
    "Dense(output_dim=output_num_units, input_dim=hidden5_num_units, activation='softmax'),\n",
    " ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "trained_model_5d = model.fit(x_train, y_train, nb_epoch=epochs, batch_size=batch_size, validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "datagen = ImageDataGenerator(zca_whitening=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading data\n",
    "train = pd.read_csv(os.path.join(data_dir, 'Train', 'train.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = []\n",
    "for img_name in train.filename:\n",
    " image_path = os.path.join(data_dir, 'Train', 'Images', 'train', img_name)\n",
    " img = imread(image_path, flatten=True)\n",
    " img = img.astype('float32')\n",
    " temp.append(img)\n",
    " \n",
    "x_train = np.stack(temp)\n",
    "\n",
    "X_train = x_train.reshape(x_train.shape[0], 1, 28, 28)\n",
    "\n",
    "X_train = X_train.astype('float32')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit parameters from data\n",
    "datagen.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## splitting\n",
    "y_train = keras.utils.np_utils.to_categorical(train.label.values)\n",
    "split_size = int(x_train.shape[0]*0.7)\n",
    "\n",
    "x_train, x_test = X_train[:split_size], X_train[split_size:]\n",
    "y_train, y_test = y_train[:split_size], y_train[split_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## reshaping\n",
    "x_train=np.reshape(x_train,(x_train.shape[0],-1))/255\n",
    "x_test=np.reshape(x_test,(x_test.shape[0],-1))/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## structure using dropout\n",
    "from keras.layers.core import Dropout\n",
    "model = Sequential([\n",
    " Dense(output_dim=hidden1_num_units, input_dim=input_num_units, activation='relu'),\n",
    " Dropout(0.25),\n",
    " Dense(output_dim=hidden2_num_units, input_dim=hidden1_num_units, activation='relu'),\n",
    " Dropout(0.25),\n",
    " Dense(output_dim=hidden3_num_units, input_dim=hidden2_num_units, activation='relu'),\n",
    " Dropout(0.25),\n",
    " Dense(output_dim=hidden4_num_units, input_dim=hidden3_num_units, activation='relu'),\n",
    " Dropout(0.25),\n",
    " Dense(output_dim=hidden5_num_units, input_dim=hidden4_num_units, activation='relu'),\n",
    " Dropout(0.25),\n",
    "\n",
    "Dense(output_dim=output_num_units, input_dim=hidden5_num_units, activation='softmax'),\n",
    " ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "trained_model_5d = model.fit(x_train, y_train, nb_epoch=epochs, batch_size=batch_size, validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "trained_model_5d = model.fit(x_train, y_train, nb_epoch=epochs, batch_size=batch_size, validation_data=(x_test, y_test)\n",
    " , callbacks = [EarlyStopping(monitor='val_acc', patience=2)])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
